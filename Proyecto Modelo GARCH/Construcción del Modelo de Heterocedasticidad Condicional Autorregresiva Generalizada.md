# **Construcci√≥n del Modelo de Heterocedasticidad Condicional Autorregresiva Generalizada**
![Python](https://img.shields.io/badge/Python-3.13-yellow)
![Status](https://img.shields.io/badge/Status-Complete-green)

Es un modelo econom√©trico que permite evaluar y modelar la volatilidad en series de tiempo financieras. Plantea que existe autocorrelaci√≥n en la varianza de series temporales y; que esta no es constante en el tiempo. De manera que, reconoce que la volatilidad financiera no es uniforme y que los periodos de alta volatilidad tiende a generar cl√∫steres.
La varianza depende tanto de errores pasados como de sus valores tomados en el pasado, puesto que los mercados no se comportan √∫nicamente de manera aleatoria.

## **Especificaci√≥n del modelo**

Orden del GARCH(p, q):
> - *p*: N√∫mero de t√©rminos autorregresivos de la varianza (GARCH).
> - *q*: N√∫mero de t√©rminos de los errores al cuadrado (ARCH).

## **Distribuci√≥n de los errores:**

- Normal (Gaussiana).
- t-Student (para capturar colas pesadas).
- Distribuci√≥n Generalizada de Errores (GED).
  
**Principales propiedades**
- **No estacionariedad** en la varianza.
- **Estacionariedad en la media:** La serie debe ser estacionaria en su componente de media. Caso contrario, se deben aplicar transformaciones como la diferenciaci√≥n (para eliminar tendencias) o transformaciones log, Box-Cox para estabilizar la media.
- **Ausencia de autocorrelaci√≥n en la media:** Si hay autocorrelaci√≥n, primero se debe modelar la media con un proceso ARMA(p,q) mediante un modelo ARMA-GARCH
  
- Alpha debe ser positivo, as√≠ garantiza una varianza positiva.
- Los sucesos m√°s recientes generan mayor efecto.
- La sumatoria de alpha y beta debe de permanecer entre 0 y 1

## **Par√°metros que se estiman en un modelo GARCH(p, q)**
- *Œº* (mu): Representa la media condicional de la serie temporal
- *œâ* (omega): Es el t√©rmino constante en la ecuaci√≥n de la varianza condicional.
- *Œ±* (alfa): Son los coeficientes de los t√©rminos ARCH; es decir, de los errores pasados al cuadrado.
- *Œ≤* (beta): Son los coeficientes de los t√©rminos GARCH; es decir, de la volatilidad condicional pasada.
  
## **Pruebas preliminares**
- **Test de estacionariedad:** Aplicar pruebas como ADF (Augmented Dickey-Fuller) o KPSS para verificar estacionariedad en la media.
- **Detecci√≥n de heterocedasticidad:** Gr√°ficos de autocorrelaci√≥n (ACF/PACF) de los residuos al cuadrado.
- **Test ARCH-LM (Lagrange Multiplier)** para confirmar la presencia de efectos ARCH/GARCH.
- **Distribuci√≥n de los residuos:** Verificar si presentan colas pesadas (usar curtosis) o asimetr√≠a, lo que sugiere usar distribuciones no normales (ej.: t-Student, GED).

## **Evaluaci√≥n de la pertinencia del modelo**
- **Diagn√≥stico de residuos:**
  - Los residuos estandarizados deben ser ruido blanco (sin autocorrelaci√≥n en ACF/PACF).
  - Aplicar tests como Ljung-Box o ARCH-LM a los residuos al cuadrado para confirmar que no quedan efectos ARCH.
- **Criterios de informaci√≥n:** Comparar modelos usando AIC, BIC, o Log-Likelihood.
- **Estabilidad:** Verificar si los par√°metros son significativos (p-valores < 0.05).

# **Configuraci√≥n y descarga de datos**

```python
!pip install yfinance
!pip install arch
```
```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import yfinance as yf
import scipy.stats as stats
import yfinance as yf
from arch import arch_model
from statsmodels.stats.diagnostic import het_arch
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.tsa.stattools import acf, pacf
from typing import Union, List
from datetime import datetime, timedelta

def configure_analysis(stock, years=5):
    end_date = datetime.now()

    start_date = end_date - timedelta(days=years * 252)
    return start_date, end_date

def data_download(start_date, end_date, stock_symbols):
    try:
        prices = yf.download(stock_symbols, start=start_date, end=end_date)['Close']
        if isinstance(prices, pd.Series):
            prices = pd.DataFrame(prices)
        if prices.empty:
          raise ValueError("No se obtuvieron datos de precios")
        return prices
    except Exception as e:
        raise ValueError(f"Error al descargar datos: {str(e)}")
```
```python
if __name__ == "__main__":
    stock = ["COST"]
    start_date, end_date = configure_analysis(stock)
    try:
        prices = data_download(start_date, end_date, stock)
    except ValueError as e:
        print(f"Error al descargar datos: {e}")
        exit()
    print(f"Datos descargados:\n{prices.head()}\n")
```
```
[*********************100%***********************]  1 of 1 completedDatos descargados:
Ticker            COST
Date                  
2021-09-13  439.327454
2021-09-14  438.132751
2021-09-15  440.350128
2021-09-16  442.816010
2021-09-17  439.184143
```

# **Estad√≠stica y plot de precios inicial**

```python
for stock in prices.columns:
    print(prices.describe())
```

```
Ticker         COST
count    865.000000
mean     613.269908
std      174.173290
min      399.907318
25%      481.563629
50%      530.753906
75%      730.203247
max     1076.859985
```

```python
for stock in prices.columns:
    plt.figure(figsize=(10, 5))
    plt.plot(prices[stock], label=f"Precio de {stock}", color="violet")
    plt.title(f"Precio de {stock}")
    plt.xlabel("A√±o")
    plt.ylabel("Precio")
    plt.legend()
```
![image](https://github.com/user-attachments/assets/69670c60-b00f-43c4-a5ef-74dc85e2fc38)

# **C√°lculo y gr√°fico de retornos logar√≠tmicos**

```python
def log_returns(prices):
    log_retornos = np.log(prices / prices.shift(1)).dropna()
    if len(log_retornos) < 30:
        raise ValueError("No hay suficientes datos para calcular retornos.")
    return log_retornos

def plot_log_returns(log_retornos, stock):
    plt.figure(figsize=(10, 5))
    plt.plot(log_retornos[stock], label=f"Retornos Logar√≠tmicos - {stock}", color="violet")
    plt.axhline(y=0, color="purple", linestyle="--", linewidth=0.7)
    plt.title(f"Retornos Logar√≠tmicos de {stock}")
    plt.xlabel("A√±o")
    plt.ylabel("Log-retornos")
    plt.legend()
    plt.show()
```

```python
# Calcular retornos logar√≠tmicos
retornos = log_returns(prices)
print(f"Retornos logar√≠tmicos:\n{retornos.head()}\n")
plot_log_returns(retornos, stock)
```

```
Retornos logar√≠tmicos:
Ticker          COST
Date                
2021-09-14 -0.002723
2021-09-15  0.005048
2021-09-16  0.005584
2021-09-17 -0.008236
2021-09-20 -0.018383
```

![image](https://github.com/user-attachments/assets/5434d653-df30-4270-a2a9-90c0c5af10d6)


# **An√°lisis estad√≠stico de los retornos logar√≠tmicos**

```python
def analyze_log_returns(log_retornos):
  stats = {}
  for column in log_retornos.columns:
    stats[column] = {
        'Media': log_retornos[column].mean(),
        'Mediana': log_retornos[column].median(),
        'M√≠nimo valor': log_retornos[column].min(),
        'M√°ximo valor': log_retornos[column].max(),
        'Desviaci√≥n Est√°ndar': log_retornos[column].std(),
        'Asimetr√≠a': log_retornos[column].skew(),
        'Curtosis': log_retornos[column].kurtosis()
    }
  return pd.DataFrame(stats)
```

```python
print(analyze_log_returns(retornos))
```

```
                          COST
Media                 0.000992
Mediana               0.001447
M√≠nimo valor         -0.132975
M√°ximo valor          0.070078
Desviaci√≥n Est√°ndar   0.014989
Asimetr√≠a            -0.945498
Curtosis             10.046149
```

# **Correlograma de log-retornos**
- **ACF (Autocorrelation Function)** mide la correlaci√≥n entre una observaci√≥n y sus rezagos sin ajustar por los efectos de los rezagos intermedios.
- **PACF (Partial ACF)** mide la correlaci√≥n entre una observaci√≥n y un rezago espec√≠fico, eliminando el impacto de los rezagos intermedios.
  > - Si el PACF muestra un corte abrupto en un rezago espec√≠fico, sugiere un modelo AR(p) de orden ùëù
  > - Si el PACF se desvanece lentamente, puede ser indicio de un modelo m√°s complejo (como un ARMA).

```python
def plot_correlogram(log_retornos: Union[pd.Series, pd.DataFrame], lags: int = 40, alpha: float = 0.05):
    """
    Crea un correlograma de ACF y PACF
    """
    def calcular_bandas_confianza(n_obs: int, alpha: float) -> float:
        return np.sqrt(1 / n_obs) * stats.norm.ppf(1 - alpha / 2)

    fig, axes = plt.subplots(2, 1, figsize=(10, 8))

    acf_vals = acf(log_retornos, nlags=lags, fft=False)
    pacf_vals = pacf(log_retornos, nlags=lags)

    bandas = calcular_bandas_confianza(len(log_retornos), alpha)

    axes[0].stem(range(lags + 1), acf_vals[:lags + 1], linefmt="b-", markerfmt="bo", basefmt="r-")
    axes[0].axhline(y=0, color="black", linestyle="-")
    axes[0].axhline(y=bandas, color="red", linestyle="--")
    axes[0].axhline(y=-bandas, color="red", linestyle="--")
    axes[0].set_title("ACF")

    axes[1].stem(range(1, lags + 1), pacf_vals[1:lags + 1], linefmt="b-", markerfmt="bo", basefmt="r-")
    axes[1].axhline(y=0, color="black", linestyle="-")
    axes[1].axhline(y=bandas, color="red", linestyle="--")
    axes[1].axhline(y=-bandas, color="red", linestyle="--")
    axes[1].set_title("PACF")

    plt.tight_layout()
    plt.show()
```

```python
plot_correlogram(retornos)
```
![image](https://github.com/user-attachments/assets/66d01f43-73ff-4c38-a06d-5217f8cd2d49)

# **Prueba ARCH-LM**
Eval√∫a si hay efectos ARCH en los residuos de la serie. Si el p-valor es bajo (<0.05), se rechaza la hip√≥tesis nula de homocedasticidad, lo que sugiere la presencia de **heterocedasticidad condicional.**

# **Prueba de Ljung-Box en los residuos al cuadrado**
Verifica si hay autocorrelaci√≥n en los residuos al cuadrado, lo que indica heterocedasticidad.

```python
def test_heteroskedasticity(log_retornos):
    """
    Realiza pruebas de heterocedasticidad en los retornos logar√≠tmicos.

    Par√°metros:
    log_retornos : pd.Series
        Serie de retornos logar√≠tmicos.

    Retorna:
    dict : Resultados de las pruebas ARCH-LM y Ljung-Box.
    """

    resultados = {}

    for stock in log_retornos.columns:
        print(f"\nResultados para {stock}:\n" + "-"*40)

        # Prueba ARCH-LM
        arch_test = het_arch(log_retornos[stock])
        p_arch = arch_test[1]  # p-valor

        # Prueba Ljung-Box en residuos al cuadrado
        lb_test = acorr_ljungbox(log_retornos[stock]**2, lags=[10], return_df=True)
        p_ljung = lb_test["lb_pvalue"].values[0]

        resultados[stock] = {
            "ARCH-LM p-valor": p_arch,
            "Ljung-Box p-valor": p_ljung
        }

        # Interpretaci√≥n de resultados
        print(f"ARCH-LM p-valor: {p_arch:.4f}")
        print(f"Ljung-Box p-valor: {p_ljung:.4f}")

        if p_arch < 0.05:
            print("Hay evidencia de heterocedasticidad (efectos ARCH detectados).")
        else:
            print("No hay evidencia significativa de heterocedasticidad.")

        if p_ljung < 0.05:
            print("Residuos al cuadrado presentan autocorrelaci√≥n (indicio de heterocedasticidad).")
        else:
            print("No hay autocorrelaci√≥n significativa en residuos al cuadrado.")

    return resultados
```

```python
test_heteroskedasticity(retornos)
```

```
Resultados para COST:
----------------------------------------
ARCH-LM p-valor: 0.0000
Ljung-Box p-valor: 0.0000
Hay evidencia de heterocedasticidad (efectos ARCH detectados).
Residuos al cuadrado presentan autocorrelaci√≥n (indicio de heterocedasticidad).
{'COST': {'ARCH-LM p-valor': 3.2134229872156907e-06,
  'Ljung-Box p-valor': 4.993714787115107e-07}}
```

# **Implementaci√≥n del Modelo GARCH**

```python
def fit_garch_model(log_retornos, stock, p=1, q=1):
    """
    Ajusta un modelo GARCH(p, q) a los retornos logar√≠tmicos de un activo.

    Par√°metros:
    -----------
    log_retornos : pd.DataFrame
        DataFrame con los retornos logar√≠tmicos.
    stock : str
        Nombre del activo a modelar.
    p : int, opcional
        N√∫mero de t√©rminos ARCH (default: 1).
    q : int, opcional
        N√∫mero de t√©rminos GARCH (default: 1).

    Retorna:
    --------
    resultado : arch.univariate.base.ARCHModelResult
        Modelo GARCH ajustado.
    """

    # Validar par√°metros p y q
    if not isinstance(p, int) or not isinstance(q, int) or p < 0 or q < 0:
        raise ValueError("Los par√°metros p y q deben ser enteros no negativos.")

    print(f"\nAjustando modelo GARCH({p},{q}) para {stock}...\n" + "-"*50)

    # Validar si el stock est√° en el DataFrame
    if stock not in log_retornos.columns:
        raise KeyError(f"La columna '{stock}' no est√° en el DataFrame de retornos.")

    # Extraer y validar la serie de retornos
    serie = log_retornos[stock].dropna() * 100  # Convertimos a porcentaje
    if serie.empty:
        raise ValueError(f"La serie de retornos para {stock} est√° vac√≠a despu√©s de eliminar NaN.")

    try:
        # Ajustar el modelo GARCH
        modelo = arch_model(serie, vol='Garch', p=p, q=q, dist='normal')
        resultado = modelo.fit(disp="off")

        # Mostrar resumen del modelo
        print("\n‚úÖ Modelo ajustado correctamente.\n")
        print(resultado.summary())

        return resultado

    except Exception as e:
        print(f"\n‚ùå Error al ajustar el modelo GARCH: {e}")
        return None
```
```python
modelo_garch = fit_garch_model(retornos, stock, p=1, q=1)
```
```
Ajustando modelo GARCH(1,1) para COST...
--------------------------------------------------

‚úÖ Modelo ajustado correctamente.

                     Constant Mean - GARCH Model Results                      
==============================================================================
Dep. Variable:                   COST   R-squared:                       0.000
Mean Model:             Constant Mean   Adj. R-squared:                  0.000
Vol Model:                      GARCH   Log-Likelihood:               -1535.97
Distribution:                  Normal   AIC:                           3079.94
Method:            Maximum Likelihood   BIC:                           3098.99
                                        No. Observations:                  864
Date:                Sun, Feb 23 2025   Df Residuals:                      863
Time:                        05:07:07   Df Model:                            1
                                Mean Model                                
==========================================================================
                 coef    std err          t      P>|t|    95.0% Conf. Int.
--------------------------------------------------------------------------
mu             0.1210  5.319e-02      2.275  2.292e-02 [1.674e-02,  0.225]
                              Volatility Model                             
===========================================================================
                 coef    std err          t      P>|t|     95.0% Conf. Int.
---------------------------------------------------------------------------
omega          0.0495  5.480e-02      0.904      0.366 [-5.786e-02,  0.157]
alpha[1]       0.0434  3.547e-02      1.223      0.221 [-2.614e-02,  0.113]
beta[1]        0.9355  5.051e-02     18.523  1.350e-76    [  0.837,  1.035]
===========================================================================

Covariance estimator: robust
```

# **Evaluaci√≥n del modelo**

```python
## **Graficar volatilidad estimada**
def plot_garch_volatility(modelo, stock):
    """
    Grafica la volatilidad condicional estimada por el modelo GARCH 1.
    """
    plt.figure(figsize=(10,5))
    plt.plot(modelo.conditional_volatility, color="purple", label="Volatilidad Estimada")
    plt.title(f"Volatilidad Condicional Estimada - {stock}")
    plt.xlabel("Fecha")
    plt.ylabel("Volatilidad (%)")
    plt.legend()
    plt.show()

plot_garch_volatility(modelo_garch, stock=list({stock}))
```
![image](https://github.com/user-attachments/assets/4ce2ab2b-bcc8-4e64-8968-f4c556285f45)

# **Verificar residuos del modelo**
```python
def check_garch_residuals(modelo):
    """
    Analiza los residuos est√°ndar del modelo GARCH.
    """
    residuos = modelo.resid / modelo.conditional_volatility

    plt.figure(figsize=(10,5))
    sns.histplot(residuos, bins=30, kde=True, color="purple")
    plt.axvline(x=0, color="black", linestyle="--")
    plt.title("Distribuci√≥n de los Residuos Estandarizados")
    plt.show()

    print("\nüìå Prueba Ljung-Box en residuos estandarizados:")
    lb_test = acorr_ljungbox(residuos, lags=[10], return_df=True)
    print(lb_test)

check_garch_residuals(modelo_garch)
```
![image](https://github.com/user-attachments/assets/309116ec-ee1d-4e31-a439-3b27e878fe81)

```
üìå Prueba Ljung-Box en residuos estandarizados:
     lb_stat  lb_pvalue
10  9.844192   0.454268
```

### **Prueba de Ljung-Box:**
Eval√∫a si hay autocorrelaci√≥n en los residuos
> - Si p-valor > 0.05: No hay autocorrelaci√≥n (bueno)
> - Si p-valor < 0.05: Existe autocorrelaci√≥n (problema)

# **Optimizaci√≥n de (p, q) en el modelo GARCH con criterios de informaci√≥n (AIC/BIC)**

```python
import itertools
def optimize_garch(log_retornos, stock, p_range=3, q_range=3):
    """
    Encuentra la mejor combinaci√≥n de (p, q) para un modelo GARCH usando AIC y BIC.

    Par√°metros:
    -----------
    log_retornos : pd.DataFrame
        DataFrame con los retornos logar√≠tmicos.
    stock : str
        Nombre del activo a modelar.
    p_range : int, opcional
        M√°ximo rezago p a evaluar (default: 3).
    q_range : int, opcional
        M√°ximo rezago q a evaluar (default: 3).

    Retorna:
    --------
    dict : Mejor modelo basado en AIC y BIC.
    """

    print(f"\nOptimizando GARCH(p,q) para {stock}...\n" + "-"*50)

    best_aic = float('inf')
    best_bic = float('inf')
    best_model_aic = None
    best_model_bic = None
    best_pq_aic = None
    best_pq_bic = None

    # Serie de retornos escalada
    serie = log_retornos[stock] * 100

    for p, q in itertools.product(range(p_range + 1), repeat=2):  # Prueba todas las combinaciones (p,q)
        if p == 0 and q == 0:  # Evitar modelo sin ARCH ni GARCH
            continue

        try:
            modelo = arch_model(serie, vol='Garch', p=p, q=q, dist='normal')
            resultado = modelo.fit(disp="off")

            if resultado.aic < best_aic:
                best_aic = resultado.aic
                best_model_aic = resultado
                best_pq_aic = (p, q)

            if resultado.bic < best_bic:
                best_bic = resultado.bic
                best_model_bic = resultado
                best_pq_bic = (p, q)

            print(f"GARCH({p},{q}) ‚Üí AIC: {resultado.aic:.3f} | BIC: {resultado.bic:.3f}")

        except:
            print(f"‚ö†Ô∏è No se pudo estimar GARCH({p},{q})")

    print("\nüìå **Mejor modelo seg√∫n AIC:** GARCH", best_pq_aic)
    print("üìå **Mejor modelo seg√∫n BIC:** GARCH", best_pq_bic)

    return {
        "best_aic_model": best_model_aic,
        "best_bic_model": best_model_bic,
        "best_pq_aic": best_pq_aic,
        "best_pq_bic": best_pq_bic
    }

best_models = optimize_garch(log_retornos=retornos, stock=list({stock}), p_range=3, q_range=3)

# Extraemos el mejor modelo
best_garch_model = best_models["best_aic_model"]
```
```
Optimizando GARCH(p,q) para ['COST']...
--------------------------------------------------
‚ö†Ô∏è No se pudo estimar GARCH(0,1)
‚ö†Ô∏è No se pudo estimar GARCH(0,2)
‚ö†Ô∏è No se pudo estimar GARCH(0,3)
GARCH(1,0) ‚Üí AIC: 3149.428 | BIC: 3163.713
GARCH(1,1) ‚Üí AIC: 3079.945 | BIC: 3098.991
GARCH(1,2) ‚Üí AIC: 3081.773 | BIC: 3105.581
GARCH(1,3) ‚Üí AIC: 3082.418 | BIC: 3110.987
GARCH(2,0) ‚Üí AIC: 3150.806 | BIC: 3169.852
GARCH(2,1) ‚Üí AIC: 3081.945 | BIC: 3105.752
GARCH(2,2) ‚Üí AIC: 3083.647 | BIC: 3112.216
GARCH(2,3) ‚Üí AIC: 3084.418 | BIC: 3117.749
GARCH(3,0) ‚Üí AIC: 3137.201 | BIC: 3161.009
GARCH(3,1) ‚Üí AIC: 3083.945 | BIC: 3112.514
GARCH(3,2) ‚Üí AIC: 3085.773 | BIC: 3119.104
GARCH(3,3) ‚Üí AIC: 3086.092 | BIC: 3124.185

üìå **Mejor modelo seg√∫n AIC:** GARCH (1, 1)
üìå **Mejor modelo seg√∫n BIC:** GARCH (1, 1)
```
# **Gr√°fico de volatilidad condicional**

```python
def plot_volatility(modelo, stock):
    plt.figure(figsize=(10, 5))
    plt.plot(modelo.conditional_volatility, color='purple', label='Volatilidad Condicional')
    plt.title(f'Volatilidad Condicional GARCH - {stock}')
    plt.xlabel('Tiempo')
    plt.ylabel('Volatilidad')
    plt.legend()
    plt.show()

plot_volatility(best_garch_model, stock=list({stock}))
```
![image](https://github.com/user-attachments/assets/70b2f1d3-8e4a-4e6f-8c48-57294419282a)

```python
def evaluate_residuals(modelo):
    residuos = modelo.resid / modelo.conditional_volatility
    plt.figure(figsize=(10, 5))
    plt.plot(residuos, label='Residuos estandarizados', color='violet')
    plt.axhline(y=0, color='black', linestyle='--')
    plt.title('Residuos Estandarizados del Modelo GARCH')
    plt.legend()
    plt.show()
    print("Ljung-Box Test para autocorrelaci√≥n de residuos:")
    print(acorr_ljungbox(residuos, lags=[10], return_df=True))
    print("\nPrueba Jarque-Bera para normalidad de residuos:")
    print(stats.jarque_bera(residuos))

evaluate_residuals(best_garch_model)
```

![image](https://github.com/user-attachments/assets/b3d5c542-9a8b-4a70-8a17-95796136981f)

```
Ljung-Box Test para autocorrelaci√≥n de residuos:
     lb_stat  lb_pvalue
10  9.844192   0.454268

Prueba Jarque-Bera para normalidad de residuos:
SignificanceResult(statistic=1610.433986856194, pvalue=0.0)
```

## **Observaci√≥n:**
No es cierto que siempre deba eliminarse toda autocorrelaci√≥n despu√©s de un GARCH. La clave es:

En la media: Los residuos crudos deben ser ruido blanco (gracias al modelo ARMA).

En la varianza: Los residuos estandarizados al cuadrado deben ser ruido blanco (gracias al GARCH).

# **Proyecci√≥n de volatilidad**

```python
def proyectar_volatilidad(log_retornos, stock, p=1, q=1, horizonte=30):
    """
    Ajusta un modelo GARCH(p, q) y proyecta la volatilidad futura.

    Par√°metros:
    -----------
    log_retornos : pd.DataFrame
        DataFrame con los retornos logar√≠tmicos.
    stock : str
        Nombre del activo a modelar.
    p : int, opcional
        N√∫mero de t√©rminos ARCH (default: 1).
    q : int, opcional
        N√∫mero de t√©rminos GARCH (default: 1).
    horizonte : int, opcional
        N√∫mero de d√≠as para proyectar la volatilidad.

    Retorna:
    --------
    forecast_volatility : np.array
        Proyecci√≥n de la volatilidad futura.
    """

    print(f"\nProyectando volatilidad con GARCH({p},{q}) para {stock}...\n" + "-"*50)

    # Validar si el stock est√° en los datos
    if stock not in log_retornos.columns:
        raise KeyError(f"‚ö†Ô∏è La columna '{stock}' no est√° en el DataFrame de retornos.")

    # Extraer y limpiar la serie de retornos
    serie = log_retornos[stock].dropna() * 100  # Convertimos a porcentaje
    if serie.empty:
        raise ValueError(f"‚ö†Ô∏è La serie de retornos para {stock} est√° vac√≠a despu√©s de eliminar NaN.")

    # Ajustar el modelo GARCH
    modelo = arch_model(serie, vol='Garch', p=p, q=q, dist='normal')
    resultado = modelo.fit(disp="off")

    # Generar la predicci√≥n de la varianza condicional
    garch_forecast = resultado.forecast(start=0, horizon=horizonte)

    # Extraer la varianza condicional esperada y convertirla en desviaci√≥n est√°ndar
    forecast_variance = garch_forecast.variance.iloc[-1].values  # √öltima fila de varianzas
    forecast_volatility = np.sqrt(forecast_variance)  # Volatilidad esperada

    print(f"\nProyecci√≥n de volatilidad ({horizonte} d√≠as):\n", forecast_volatility)

    return forecast_volatility

volatilidad_futura = proyectar_volatilidad(retornos, stock='COST', p=1, q=1, horizonte=30)
```
```
Proyectando volatilidad con GARCH(1,1) para COST...
--------------------------------------------------

Proyecci√≥n de volatilidad (30 d√≠as):
[1.367389   1.37108417 1.3746918  1.37821421 1.38165365 1.38501229
1.38829223 1.39149553 1.39462416 1.39768003 1.40066501 1.40358089
1.40642944 1.40921234 1.41193125 1.41458776 1.41718344 1.41971978
1.42219827 1.42462031 1.4269873  1.42930058 1.43156146 1.43377122
1.43593108 1.43804226 1.44010593 1.44212322 1.44409524 1.44602308]
```
